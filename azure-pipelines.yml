### Template to execute Terraform stages
parameters:
  environment: sandbox
  environmentDisplayName: Sandbox
  customer: all
  application: 
  tfServiceConnection:
  awsServiceConnection:
  tfPlanOnly: false
  regionName: us-east-1
  tfVersion:
  pipelineSrcDir:
  fluxCIDir:
  project:
  reqMongoMod:
  reqEKSMod:
  reqDocDB:
  reqSSRS:
  reqRDSmssqlMod:
  reqRDSaurora:
  reqRDSauroraPg:
  reqAmazonMQMod:
  reqRDSmysqlMod: 
  reqRDSoracleMod:
  reqEc2Mod:
  reqElasticsearchMod:
  reqElasticbeanStalkMod:
  reqElasticacheMod:
  reqS3Mod:
  artifactoryCredsVariableGroup: ArtifactoryReadOnlyAcct
  azureGitCredsVariableGroup: AzureGitCreds
  fluxVersion:
  fluxRepoBranch: main
  dependsOn: []
  checkoutTemplate:
  allow_ASG_BeanStalk_access: false
  Shared_Environment: false
  SourceAccountID:
  DBRefresh: false
  reqSecondEKS:
  folderToZip: NONE
  JFrogFileName: NONE
  JFrogFolderName: NONE
  JFrogFileDestination: lambdas
  allow_Bedrock_KMS_access: false
  AllowSNSfromApp: no
  AllowAssumedRole: no
  AllowARusersS3:
  AllowIAMroleKMS: no
  IAMrolesAllowedKMS:

stages:
  - stage: DeployInfraTo${{ parameters.environment }}
    displayName: Deploy Infra to ${{ parameters.environmentDisplayName }}
    dependsOn: ${{ parameters.dependsOn }}
    jobs:
    - job: Terraform_Deploy
      timeoutInMinutes: 0
      displayName: Terraform Pipeline (SitusAMC DevOps) - SiADoT
      pool: Self-hosted-AWS-Linux-pool

      # Variables read from https://samcado.visualstudio.com/DEVOPS_Platform_as_a_Service/_library?itemType=VariableGroups:
      #  - artifactory_user, artifactory_pass and artifactory_auth are from artifactoryCredsVariableGroup.
      #  - GitUser and GitPass are from azureGitCredsVariableGroup.
      variables:
        - group: ${{ parameters.artifactoryCredsVariableGroup }}
        - group: ${{ parameters.azureGitCredsVariableGroup }}

      steps:
      # Display PLAN or APPLY for Terraform run:
      - template: ../scripts/tf_plan_or_apply.yml
        parameters:
          tfPlanOnly: ${{ parameters.tfPlanOnly }}

      # Validate that SourceAccountID has a value if DBRefresh is true
      - template: ../scripts/test_srcAcctId_for_DBRefresh.yml
        parameters:
          SourceAccountID: ${{ parameters.SourceAccountID }}
          DBRefresh: ${{ parameters.DBRefresh }}
      # validate if fluxCIDir is set or not and if fluxCIDir is set then usingFlux variable will become true, shell will print we are using Flux.
      - bash: |
          if [ -v ${{ parameters.fluxCIDir }} ] ; then
              echo "##vso[task.setvariable variable=usingFlux]false"
              echo "We are NOT using Flux (yet)."
          else
              # TODO: Check that both project and fluxVersion parameters are also set here!!!!
              echo "##vso[task.setvariable variable=usingFlux]true"
              echo "We are using Flux!"
          fi
        displayName: Test if fluxCIDir is set or not - TFxciD

      - checkout: self
        displayName: Checkout pipeline source - CfxUSx

      - checkout: templates
        displayName: Get source from deploy-templates - hiSAZk

      - template: ../scripts/convert_application_to_applower.yml
        parameters:
          application: ${{ parameters.application }}

      - template: ../scripts/write_out_create_secret.yml
        parameters:
          application: ${{ parameters.application }}
      
      #validate if appname in .tfvars are same as application parameter's value in pipeline.yml.
      # env/environmant variable should be the name of .tfvars and if there is any error written to stderr then this task  will fail.
      - bash: |
          export APPNAME=`grep appname ${{ parameters.pipelineSrcDir }}/vars/${{ parameters.environment }}.tfvars | sed 's/appname//g' | tr -d "[:space:]" | tr -d '=' | tr -d '"'`
          echo "appname is $APPNAME from vars/${{ parameters.environment }}.tfvars"
          export APPLICATION_FROM_YML=`echo ${{ parameters.application }} | tr -d "[:space:]" | tr -d '"'`
          echo "application is $APPLICATION_FROM_YML from pipeline YML"
          if [ "$APPNAME" = "$APPLICATION_FROM_YML" ]; then
              echo "CHECK PASSED: appname from vars/${{ parameters.environment }}.tfvars equals application from pipeline YML."
          else
              echo "##vso[task.logissue type=error]ERROR: ${{ parameters.application }} was NOT found in vars/${{ parameters.environment }}.tfvars"
              echo "##vso[task.logissue type=error]ERROR: $APPNAME is NOT equal to $APPLICATION_FROM_YML"
              echo "##vso[task.logissue type=error]CAUTION: Be certain to make a backup copy of your Terraform tfstate file before changing application in YML file."
              exit 1
          fi
        failOnStderr: true
        displayName: Check appname from tfvars file matches application name from pipeline YML - Toy5x2

      #validate if env in .tfvars are same as environment parameter's value in pipeline.yml.
      # env/environmant variable should be the name of .tfvars and if there is any error written to stderr then this task  will fail.
      - bash: |
          export ENVIRONMENT=`grep -w env ${{ parameters.pipelineSrcDir }}/vars/${{ parameters.environment }}.tfvars | sed 's/env//g' | tr -d "[:space:]" | tr -d '=' | tr -d '"'`
          echo "environment is $ENVIRONMENT from vars/${{ parameters.environment }}.tfvars"
          export ENVIRONMENT_FROM_YML=`echo ${{ parameters.environment }} | tr -d "[:space:]" | tr -d '"'`
          echo "environment is $ENVIRONMENT_FROM_YML from pipeline YML"
          if [ "$ENVIRONMENT" = "$ENVIRONMENT_FROM_YML" ]; then
              echo "CHECK PASSED: environment from vars/${{ parameters.environment }}.tfvars equals environment from pipeline YML."
          else
              echo "##vso[task.logissue type=error]ERROR: ${{ parameters.environment }} was NOT found in vars/${{ parameters.environment }}.tfvars"
              echo "##vso[task.logissue type=error]ERROR: $ENVIRONMENT is NOT equal to $ENVIRONMENT_FROM_YML"
              echo "##vso[task.logissue type=error]CAUTION: Be certain to make a backup copy of your Terraform tfstate file before changing environment in YML file."
              exit 1
          fi
        failOnStderr: true
        displayName: Check environment from tfvars file matches environment from pipeline YML - r76ax7

      - template: ../scripts/get_aws_account_id.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}

      # Setting Bucket variable.
      - bash: | 
          bucket=$(echo "samc-tfstate-${{ parameters.regionName }}-${{ parameters.application }}-${{ parameters.environment }}-${{ parameters.customer }}" | tr '[:upper:]' '[:lower:]')
          echo "##vso[task.setvariable variable=backendBucket]$bucket"
          echo "backendBucket is $bucket"
          printf 'terraform { \nbackend "s3" {} \n}' > ${{ parameters.pipelineSrcDir }}/s3_bucket_required_for_saving_state.tf
          echo "pipelineSrcDir is ${{ parameters.pipelineSrcDir }}"
          ls -l ${{ parameters.pipelineSrcDir }}
        displayName: Setting bucket variable - bN6KKg
      
      #check the s3 bucket and create if not present in the given awsServiceConnection.
      #new s3 bucket will create only if region is us-east-1.
      - task: AWSShellScript@1
        displayName: Create S3 if not present and tag bucket - BycttB
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            if [ "${{ parameters.regionName }}" = "us-east-1" ]; then
              export BUCKET_CONSTRAINT=""
            else
              export BUCKET_CONSTRAINT=" --create-bucket-configuration LocationConstraint=${{ parameters.regionName }}"
            fi

            if aws s3 ls "s3://$(backendBucket)" 2>&1 | grep -q 'NoSuchBucket'
            then
              aws s3api create-bucket --bucket $(backendBucket) $BUCKET_CONSTRAINT
            fi
 
            echo "Now tag S3 bucket with samc:appid and samc:env as follows:"
            export TAG_SET="TagSet=[{Key='samc:appid',Value=${{ parameters.application }}},{Key='samc:env',Value=${{ parameters.environment }}},{Key='samc:costcenter',Value="904IT2"},{Key='samc:ea',Value="60581"},{Key='samc:eai',Value="61001"},{Key='samc:product',Value="AWS_Platform"},{Key='samc:client',Value="Internal"},{Key='samc:backup',Value="None"},{Key='Name',Value="$(backendBucket)"}]"
            echo "TAG_SET is: $TAG_SET"
            aws s3api put-bucket-tagging --bucket $(backendBucket) --tagging "$TAG_SET"

      - template: ../scripts/account_lookup.yml
        parameters:
          ACCT_ID: $ACCOUNT_ID
      
      # Enabling Bucket versioning for the newly created bucket.
      - task: AWSCLI@1
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          awsCommand: 's3api'
          awsSubCommand: 'put-bucket-versioning'
          awsArguments: "--bucket $(backendBucket) --versioning-configuration Status=Enabled"
        displayName: Enabling Versioning - Tg8JaP
      
      #Blocking public access for the newly created bucket.
      - task: AWSCLI@1
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          awsCommand: 's3api'
          awsSubCommand: 'put-public-access-block'
          awsArguments: "--bucket $(backendBucket) --public-access-block-configuration \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\""
        displayName: Blocking Public Access Versioning - ujTrM9
      
      #Copy files to s3
      - template: ../ami_creation/copy_files_to_s3.yml
        parameters:
          s3BucketNameToCopyAMIFiles: ${{ parameters.s3BucketNameToCopyAMIFiles }}
          repoPathforAMIFiles: ${{ parameters.repoPathforAMIFiles }}
          createAMI: ${{ parameters.createAMI }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
        
      # Checkout Repos.
      - template: ./${{ parameters.checkoutTemplate }}@self
        parameters:
          reqEKSMod: ${{ parameters.reqEKSMod}}
          reqMongoMod: ${{ parameters.reqMongoMod}}
          reqSSRS: ${{ parameters.reqSSRS}}
          reqRDSmssqlMod: ${{ parameters.reqRDSmssqlMod}}
          reqRDSaurora: ${{ parameters.reqRDSaurora}}
          reqAmazonMQMod: ${{ parameters.reqAmazonMQMod}}
          reqNLBMod: ${{ parameters.reqNLBMod}}
          reqEFSMod: ${{ parameters.reqEFSMod}}
          reqRDSmysqlMod: ${{ parameters.reqRDSmysqlMod}}
          reqRDSoracleMod: ${{ parameters.reqRDSoracleMod}}
          reqEc2Mod: ${{ parameters.reqEc2Mod}}
          reqElasticsearchMod: ${{ parameters.reqElasticsearchMod}}
          reqElasticbeanStalkMod: ${{ parameters.reqElasticbeanStalkMod}}
          reqElasticacheMod: ${{ parameters.reqElasticacheMod}}
          reqS3Mod: ${{ parameters.reqS3Mod}}

      - bash: |
          if [ -d "PySRE" ]; then
              echo "Copying PySRE now to ${{ parameters.pipelineSrcDir }}:"
              cp -r PySRE ${{ parameters.pipelineSrcDir }}/
              ls -l ${{ parameters.pipelineSrcDir }}
              echo "PySRE copied to ${{ parameters.pipelineSrcDir }} ^ as shown above."
          else
              echo "PySRE does not exist so no folder copy was done."
          fi
        displayName: Prepare SaaS Now application monitor library deployment - SNAZ6t

      # Delete unnecesary files by stages.
      - template: ../scripts/delete_unnecesary_repos.yml
        parameters:
          IAC_phase: ${{ parameters.IAC_phase }}

      # Create KMS key if it is not exist.
      - template: ../scripts/kms_script.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          application: ${{ parameters.application }}
          environment: ${{ parameters.environment }}

      # Create KMS Key Policy TEMPLATE for shared environments, DBRefresh & where BeanStalk and/or auto scaling groups are used
      - template: ../scripts/prep_app_share_kms_key_policy.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          application: ${{ parameters.application }}
          environment: ${{ parameters.environment }}
          allow_ASG_BeanStalk_access: ${{ parameters.allow_ASG_BeanStalk_access }}
          DBRefresh: ${{ parameters.DBRefresh }}
          Shared_Environment: ${{ parameters.Shared_Environment }}
          allow_Bedrock_KMS_access: ${{ parameters.allow_Bedrock_KMS_access }}
          AllowSNSfromApp: ${{ parameters.AllowSNSfromApp }}
          AllowAssumedRole: ${{ parameters.AllowAssumedRole }}
          AllowARusersS3: ${{ join(' ', parameters.AllowARusersS3) }}
          AllowIAMroleKMS: ${{ parameters.AllowIAMroleKMS }}
          IAMrolesAllowedKMS: ${{ join(' ', parameters.IAMrolesAllowedKMS) }}

      # Transform the template created above:
      - template: ../scripts/template_file_transformer.yml
        parameters:
          templateFile: "kms-key-policy.json"
          transformedFolder: "transformed"
          templateFolder: $(CURRENT_KMS_DIR)
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          String1toReplace: "SOURCE_ACCOUNT_ID"
          String1value: ${{ parameters.SourceAccountID }}
          String2toReplace: "AWS_REGION"
          String2value: ${{ parameters.regionName }}
          String3toReplace: "AWS_ACCOUNT_ID"
          String3value: $(ACCOUNT_ID)
          String4toReplace: "SAMC_ENV"
          String4value: ${{ parameters.environment }}
          String5toReplace: "SAMC_APPID"
          String5value:  ${{ parameters.application }}
          String6toReplace: "KMS_KEY_ID"
          String6value: $(kms_key_id)
          String7toReplace: "ALLOW_SNS_FROM_APP"
          String7value: ${{ parameters.AllowSNSfromApp }}
          String8toReplace: "ALLOW_ASSUMED_ROLE"
          String8value: ${{ parameters.AllowAssumedRole }}

      # Deploy the transformed KMS key IAM policy
      - template: ../scripts/put_kms_transformed.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}

      # Create CI_CD secrets.
      - template: ../scripts/create_CI_CD_secrets.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          application: ${{ parameters.application }}
          environment: ${{parameters.environment}}
          regionName: ${{ parameters.regionName }}
          art_user: $(artifactory_user)
          art_pass: $(artifactory_pass)
          art_auth: $(artifactory_auth)
          git_user: $(GitUser)
          git_pass: $(GitPass)
      
      # Create Amazon MQ secrets for admin & appuser if parameters.reqAmazonMQMod is true. 
      # and Amazon MQ secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create Amazon MQ secrets for admin & appuser if they do not yet exist - CAMQSA
        condition: eq('${{ parameters.reqAmazonMQMod}}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |   
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) activemq
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rabbitmq
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) activemq
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rabbitmq
      
      # Create grafana prometheus secret if it does not yet exist.
      - task: AWSShellScript@1
        displayName: Create grafana prometheus secret if it does not yet exist - CgpsiN
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) grafana-prometheus

      # Create DocumentDB "master" user secret if parameters.reqDocDB is true and secret does not yet exist.
      - task: AWSShellScript@1
        displayName: Create DocumentDB master user secret if it does not yet exist - DcDBXz
        condition: eq('${{ parameters.reqDocDB }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret master $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) documentdb

      # Create SSRS RDS-MSSQL secrets if parameters.reqSSRS is true. 
      # and SSRS RDS-MSSQL secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create SSRS RDS-MSSQL secrets if they do not yet exist - CSSRSs
        condition: eq('${{ parameters.reqSSRS }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) ssrs-rdsmssql
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) ssrs-rdsmssql
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) ssrs-rdsmssql
            $(CURRENT_CS_DIR)/createsecret rdsmasteradmin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) ssrs-rdsmssql

      # Create RDS mssql secrets if parameters.reqRDSmssqlMod is true. 
      # and RDS mssql secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create RDS mssql secrets if they do not yet exist CRmsiN
        condition: eq('${{ parameters.reqRDSmssqlMod }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mssql
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mssql
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mssql

      # Create RDS-Aurora secrets if parameters.reqRDSaurora is true.
      # and RDS-Aurora secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create RDS-Aurora secrets if they do not yet exist - CRAsiN
        condition: eq('${{ parameters.reqRDSaurora }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora

      # Create RDS-Aurora PostgreSQL secrets if parameter reqRDSauroraPg is true.
      # and RDS-Aurora PostgreSQL secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create RDS-Aurora PostgreSQL secrets if they do not yet exist - RDSAps
        condition: eq('${{ parameters.reqRDSauroraPg }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret postmast $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-aurora

      # Create RDS mysql secrets if parameters.reqRDSmysqlMod is true. 
      # and RRDS mysql secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create RDS mysql secrets if they do not yet exist - CRMYsi
        condition: eq('${{ parameters.reqRDSmysqlMod }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mysql
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mysql
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-mysql

      # Create RDS oracle secrets if parameters.reqRDSoracleMod is true. 
      # and RDS oracle secrets do not yet exist.
      - task: AWSShellScript@1
        displayName: Create RDS oracle secrets if they do not yet exist - CROsiN
        condition: eq('${{ parameters.reqRDSoracleMod }}', true)
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            $(CURRENT_CS_DIR)/createsecret admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-oracle
            $(CURRENT_CS_DIR)/createsecret app_admin $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-oracle
            $(CURRENT_CS_DIR)/createsecret appuser $(APPLOWER) ${{parameters.environment}} ${{ parameters.regionName }} $(kms_key_id) rds-oracle

      # Create ZIP file from folder - mostly for Lambda deployments
      - template: ../scripts/create_zip_file_from_folder.yml
        parameters:
          folder_to_zip: ${{ parameters.folderToZip }}
          workingDirectory: ${{ parameters.pipelineSrcDir }}

      # Install Terraform version parameters.tfVersion.
      - task: ms-devlabs.custom-terraform-tasks.custom-terraform-installer-task.TerraformInstaller@1
        displayName: Install Terraform v${{ parameters.tfVersion }} - iTNL63
        inputs:
          terraformVersion: ${{ parameters.tfVersion }}

      # Copy file from JFrog Artifactory to JFrogFileDestination folder
      - template: ../scripts/copy_from_JFrog_to_folder.yml
        parameters:
          JFrogFileName: ${{ parameters.JFrogFileName }}
          JFrogFolderName: ${{ parameters.JFrogFolderName }}
          JFrogFileDestination: ${{ parameters.JFrogFileDestination }}

      # Add Terraform variable values from "customer" & "JFrogFileName" parameters by adding to <env>.tfvars
      - template: ../scripts/create_tfVar_customer_AppClient.yml
        parameters:
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          customer: ${{ parameters.customer }}
          environment: ${{ parameters.environment }}
          JFrogFileName: ${{ parameters.JFrogFileName }}

      # Terraform initialize.
      - task: TerraformTask@5
        displayName: Terraform Init - TiNmvh5
        inputs:
          provider: 'aws'
          command: 'init'
          backendServiceAWS: ${{ parameters.tfServiceConnection }}
          backendAWSBucketName: "$(backendBucket)"
          backendAWSKey: ${{ parameters.environment }}.tfstate
          workingDirectory: ${{ parameters.pipelineSrcDir }}

      # Terraform Validate.
      - task: TerraformTask@5
        displayName: Terraform validate - TtVMmE5
        inputs:
          provider: 'aws'
          command: 'validate'
          workingDirectory: ${{ parameters.pipelineSrcDir }}
    
      # Terraform Plan.
      - task: TerraformTask@5
        condition: always()
        displayName: Terraform plan - TpbanQ5
        inputs:
          provider: 'aws'
          command: 'plan'
          commandOptions: '--var-file vars/${{ parameters.environment }}.tfvars -var="artifactory_user=$(artifactory_user)" -var="artifactory_pass=$(artifactory_pass)" -out tfplan'
          environmentServiceNameAWS: ${{ parameters.tfServiceConnection }}
          workingDirectory: ${{ parameters.pipelineSrcDir }}

      # Terraform Apply with a condition that parameters.tfPlanOnly is false.
      # name is needed to store the output variables in a json file, when we are using on AMI pipeline
      - task: TerraformTask@5
        name: terraformApply
        displayName: Terraform Apply - TACSyV5
        inputs:
          provider: 'aws'
          command: 'apply'
          commandOptions: 'tfplan'
          environmentServiceNameAWS: ${{ parameters.tfServiceConnection }}
          workingDirectory: ${{ parameters.pipelineSrcDir }}
        condition: eq('${{ parameters.tfPlanOnly}}', false)

      # Create configuration reports for deployed instances to be posted to MonitoringDashboard account:
      - template: ../monitoring/create_instance_config_reports.yml
        parameters:
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}

      #Copy files to s3 for image builder, s3 bucket is creating as a part of imagebuilder infra configuration
      - template: ../ami_creation/copy_files_to_s3_for_Image_Builder.yml
        parameters:
          s3BucketNameToCopyAMIFiles: ${{ parameters.s3BucketNameToCopyAMIFiles }}
          repoPathforAMIFiles: ${{ parameters.repoPathforAMIFiles }}
          copyFilesTos3BucketImageBuilder: ${{ parameters.copyFilesTos3BucketImageBuilder }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
        
        #create terraform ouput as pipeline variables for ami creation
      - template: ../ami_creation/create_terraform_output_as_pipeline_variables.yml
        parameters:
          createAMI: ${{ parameters.createAMI }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          UpdateLinuxAMI: ${{parameters.UpdateLinuxAMI}}
          UpdateWindowsAMI: ${{parameters.UpdateWindowsAMI}}
        
        # AWS SSM Automation to execute update windows/windows elasticbeanstalk ami document
      - template: ../ami_creation/copy_files_to_s3_for_aws_ssm_Automation.yml
        parameters:
          s3BucketNameToCopyAMIFiles: ${{ parameters.s3BucketNameToCopyAMIFiles }}
          repoPathforAMIFiles: ${{ parameters.repoPathforAMIFiles }}
          UpdateLinuxAMI: ${{parameters.UpdateLinuxAMI}}
          UpdateWindowsAMI: ${{parameters.UpdateWindowsAMI}}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}

        # AWS SSM Automation to execute update linux ami document
      - template: ../ami_creation/aws_ssm_document_execution_for_Linux.yml
        parameters:
          InstanceType: ${{parameters.InstanceType}}
          SecurityGroupIds: ${{parameters.SecurityGroupIds}}
          SubnetId: ${{parameters.SubnetId}}
          PreUpdateScript: ${{parameters.PreUpdateScript}}
          PostUpdateScript: ${{parameters.PostUpdateScript}}
          IncludePackages: ${{parameters.IncludePackages}}
          ExcludePackages: ${{parameters.ExcludePackages}}
          sourceType: ${{parameters.sourceType}}
          workingDirectory: ${{parameters.workingDirectory}}
          UpdateLinuxAMI: ${{parameters.UpdateLinuxAMI}}
          regionName: ${{parameters.regionName}}
          awsServiceConnection: ${{parameters.awsServiceConnection}}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          TargetAmiName: ${{parameters.TargetAmiName}}
          TargetImageDescription: ${{parameters.TargetImageDescription}}
          s3BucketNameToCopyAMIFiles: ${{parameters.s3BucketNameToCopyAMIFiles}}
          repoPathforAMIFiles: ${{ parameters.repoPathforAMIFiles }}
          ShellScriptName: ${{ parameters.ShellScriptName }}
        
        # AWS SSM Automation to execute update windows/windows elasticbeanstalk ami document
      - template: ../ami_creation/aws_ssm_document_execution_for_windows_AMI.yml
        parameters:
          regionName: ${{parameters.regionName}}
          awsServiceConnection: ${{parameters.awsServiceConnection}}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          UpdateWindowsAMI: ${{parameters.UpdateWindowsAMI}}
          TargetAmiName: ${{parameters.TargetAmiName}}
          TargetImageDescription: ${{parameters.TargetImageDescription}}
          InstanceType: ${{parameters.InstanceType}}
          SecurityGroupIds: ${{parameters.SecurityGroupIds}}
          SubnetId: ${{parameters.SubnetId}}
          IncludeKbs: ${{parameters.IncludeKbs}}
          PreUpdateScript: ${{parameters.PreUpdateScript}}
          PostUpdateScript: ${{parameters.PostUpdateScript}}
          sourceType: ${{parameters.sourceType}}
          workingDirectory: ${{parameters.workingDirectory}}
          AllowReboot: ${{parameters.AllowReboot}}
          s3BucketNameToCopyAMIFiles: ${{parameters.s3BucketNameToCopyAMIFiles}}
          repoPathforAMIFiles: ${{ parameters.repoPathforAMIFiles }}
          PowershellScriptName: ${{ parameters.PowershellScriptName }}

        # AWS SSM Automation execution status
      - template: ../ami_creation/check_aws_ssm_automation_status.yml
        parameters:
          regionName: ${{parameters.regionName}}
          awsServiceConnection: ${{parameters.awsServiceConnection}}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          UpdateLinuxAMI: ${{parameters.UpdateLinuxAMI}}
          UpdateWindowsAMI: ${{parameters.UpdateWindowsAMI}}
          application: ${{ parameters.application }}

        # check_instance_status
      - template: ../ami_creation/check_instance_status.yml
        parameters:
          createAMI: ${{ parameters.createAMI }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}

        #create_ami
      - template: ../ami_creation/create_ami.yml
        parameters:
          createAMI: ${{ parameters.createAMI }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          platformName: ${{ parameters.platformName }}

      
      # EKS Post Deployment steps and this task will run only if parameters.reqEKSMod is true and parameters.tfPlanOnly is false.
      # Configure flux, aws-iam-authenticator.
      # script will Apply standard yaml from eks-cluster/eks-yaml, Pod Security from eks-standards/standards, and app-specific ${{ parameters.pipelineSrcDir }}/eks-yaml.
      - task: AWSShellScript@1
        displayName: EKS Post Deployment steps for ${{ parameters.environmentDisplayName }} - EKSpds
        inputs:
          awsCredentials: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          scriptType: inline
          inlineScript: |
            export theeWorkinDir=$PWD
            echo "The current working directory is: $theeWorkinDir"
            pwd
            echo "Setup local build agent to interact with EKS cluster"
            curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/linux/amd64/aws-iam-authenticator
            chmod +x ./aws-iam-authenticator
            mkdir -p $HOME/bin && cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator && export PATH=$PATH:$HOME/bin
            echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
            aws-iam-authenticator version
            rm ./aws-iam-authenticator
            if [[ "${{ parameters.reqSecondEKS }}" == "true" ]]; then
                export CLUSTERNAME=$(aws eks list-clusters --output text | sed -e 's/\t/\n/g' | egrep "^${{ parameters.application }}\b" | grep "\b${{ parameters.environment }}\b" | grep "eks2" )
            else
                export CLUSTERNAME=$(aws eks list-clusters --output text | sed -e 's/\t/\n/g' | egrep "^${{ parameters.application }}\b" | grep "\b${{ parameters.environment }}\b" | grep "eks" ) 
            fi
            echo   CLUSTERNAME is $CLUSTERNAME
            export KUBECONFIG=${{ parameters.pipelineSrcDir }}/kubeconfig.yml
            aws eks update-kubeconfig --name $CLUSTERNAME --kubeconfig $KUBECONFIG
            kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION=false
            kubectl set env daemonset aws-node -n kube-system WARM_IP_TARGET=1
            if [ -d "${{ parameters.fluxCIDir }}/clusters/bootstrap/flux-system/" ] ; then
              echo "Installing flux into EKS cluster"
              echo "Download and install flux CLI"
              cd /tmp; wget https://github.com/fluxcd/flux2/releases/download/v${{ parameters.fluxVersion }}/flux_${{ parameters.fluxVersion }}_linux_amd64.tar.gz ; \
                gunzip flux_${{ parameters.fluxVersion }}_linux_amd64.tar.gz ; \
                tar -xvf flux_${{ parameters.fluxVersion }}_linux_amd64.tar ; \
                sudo mv flux /usr/local/bin/
              cd $theeWorkinDir
              pwd
              /usr/local/bin/flux check --pre
              kubectl apply -f ${{ parameters.fluxCIDir }}/clusters/bootstrap/flux-system/gotk-components.yaml
              echo "Setup required kubernetes resources for flux operations"
              echo Artifactory User is $(artifactory_user)
              echo Git User is $(GitUser)
              kubectl create secret docker-registry regcred --docker-server=samc-docker.jfrog.io --docker-username=$(artifactory_user) \
                --docker-password=$(artifactory_pass) --namespace=flux-system --dry-run=client -o yaml | kubectl apply -f -
              kubectl create secret generic samc-jfrog-helm-cred --from-literal=username=$(artifactory_user) --from-literal=password=$(artifactory_pass) \
                --namespace=flux-system --dry-run=client -o yaml | kubectl apply -f -
              kubectl create secret generic samc-azure-git-cred --from-literal=username=$(GitUser) --from-literal=password=$(GitPass) --namespace=flux-system \
                --dry-run=client -o yaml | kubectl apply -f -
              echo "Adding Git source repo to be connected to flux"
              /usr/local/bin/flux create source git flux-system --git-implementation=libgit2 \
                --url=https://dev.azure.com/samcado/${{ parameters.project }}/_git/${{ parameters.fluxCIDir }} \
                --branch=${{ parameters.fluxRepoBranch }} --username=$(GitUser) --password=$(GitPass) --interval=1m
              echo "Deploy flux into EKS cluster"
              kubectl create secret docker-registry regcred --docker-server=samc-docker.jfrog.io --docker-username=$(artifactory_user) \
                --docker-password=$(artifactory_pass) --dry-run=client -o yaml | kubectl apply -f -
              /usr/local/bin/flux create kustomization flux-system --source=flux-system --path="./clusters/${{ parameters.environment }}" --prune=true --interval=5m
            else
              echo "The parameter fluxCIDir was not passed in with pipeline. Skipping flux install."
            fi
            echo "Installing EFS CSI driver used by kubernetes to use AWS EFS service"
            kubectl apply -k "github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/ecr/?ref=release-1.7"
            echo Set env vars
            echo   ACCOUNT_ID is $ACCOUNT_ID
            export REGION=${{ parameters.regionName }}
            echo   REGION is $REGION
            export APPLOWER=$(echo "${{ parameters.application }}" | tr '[:upper:]' '[:lower:]')
            export APPENV="${{ parameters.environment }}"
            echo   APPLOWER is $APPLOWER
            echo   APPENV   is $APPENV
            echo "Apply standard yaml from eks-cluster/eks-yaml, eks-cluster-v11/eks-yaml, Pod Security from eks-standards/standards, and app-specific ${{ parameters.pipelineSrcDir }}/eks-yaml :"
            for yamldir in "eks-cluster/eks-yaml" "eks-cluster-v11/eks-yaml" "eks-standards/standards" "${{ parameters.pipelineSrcDir }}/eks-yaml" ; do
              if [ -d "${yamldir}" ] ; then
                cd "${yamldir}"
                # This scheme achieves ordered application of yaml, both local and remote, via filename pattern
                for f in [a-zA-Z0-9]* ; do
                  echo   Processing $f
                  if [[ "${f}" == *.url ]] ; then
                    # This file just has one line, the url for a remote yaml
                    kubectl apply -f $(< "${f}") --kubeconfig "../../${KUBECONFIG}"
                  elif [[ "${f}" == *.kustomize ]] ; then
                    # This file just has one line, the url for a remote kustomize yaml
                    kubectl apply -k $(< "${f}") --kubeconfig "../../${KUBECONFIG}"
                  elif [[ "${f}" == *.yaml ]] ; then
                    kubectl apply -f "${f}" --kubeconfig "../../${KUBECONFIG}"
                  elif [[ "${f}" == *.yml ]] ; then
                    sed -i -e "s/ACCOUNT_ID/$ACCOUNT_ID/g" "$f"
                    sed -i -e "s/CLUSTER_NAME/$CLUSTERNAME/g" "$f"
                    sed -i -e "s/REGION/$REGION/g" "$f"
                    sed -i -e "s/APPLOWER/$APPLOWER/g" "$f"
                    sed -i -e "s/APPENV/$APPENV/g" "$f"
                    kubectl apply -f "${f}" --kubeconfig "../../${KUBECONFIG}"
                  else
                    echo "Unrecognized file pattern: $f"
                  fi
                done
                cd ../..
              fi
            done
        condition: and(succeeded(), eq('${{ parameters.reqEKSMod }}', true), eq('${{ parameters.tfPlanOnly }}', false))

      # Publish the kubeconfig.yml file used to make connections to the EKS cluster:
      - publish: ${{ parameters.pipelineSrcDir }}/kubeconfig.yml
        artifact: kubeconfig-${{ parameters.regionName }}-${{ parameters.application }}-${{ parameters.environment }}
        condition: and( eq('${{ parameters.reqEKSMod }}', true), eq('${{ parameters.tfPlanOnly }}', false))

      # Monitoring setup.
      - template: ../monitoring/setup_monitoring.yml
        parameters:
          reqEKSMod: ${{ parameters.reqEKSMod }}
          reqMongoMod: ${{ parameters.reqMongoMod }}
          reqRDSmssqlMod: ${{ parameters.reqRDSmssqlMod }}
          reqElasticsearchMod: ${{ parameters.reqElasticsearchMod }}
          reqEFSMod: ${{ parameters.reqEFSMod }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          environment: ${{ parameters.environment }}
          application: ${{ parameters.application }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          reqSecondEKS: ${{ parameters.reqSecondEKS }}

      # Set up Datadog on eks.
      - template: ../monitoring/setup_datadog_eks.yml
        parameters:
          environmentDisplayName: ${{ parameters.environmentDisplayName }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          pipelineSrcDir: ${{ parameters.pipelineSrcDir }}
          tfPlanOnly: ${{ parameters.tfPlanOnly }}
          DataDogApiKey: ${{ parameters.DataDogApiKey }}
          DDRandomToken: ${{ parameters.DDRandomToken }}

      # Configure MSSQL.
      - template: ../configure_MSSQL/configure_MSSQL.yml
        parameters:
          reqSSRS: ${{ parameters.reqSSRS }}
          reqRDSmssqlMod: ${{ parameters.reqRDSmssqlMod }}
          awsServiceConnection: ${{ parameters.awsServiceConnection }}
          regionName: ${{ parameters.regionName }}
          environment: ${{ parameters.environment }}
          application: ${{ parameters.application }}
          awsAcctName: $ACCOUNT_NAME
          tfPlanOnly: ${{ parameters.tfPlanOnly }}

      # Clean out /tmp folder:
      - template: ../scripts/cleanup_local_temp_folder.yml
        parameters:
          folderName: /tmp/*

      # Clean out $(Agent.BuildDirectory) folder:
      - template: ../scripts/cleanup_local_temp_folder.yml
        parameters:
          folderName: $(Agent.BuildDirectory)
